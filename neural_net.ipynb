{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Convolutional neural network built with Keras.\"\"\"\n",
    "\n",
    "from utils import print_json\n",
    "\n",
    "import keras\n",
    "from keras.layers.core import K  # import keras.backend as K\n",
    "from keras.optimizers import Adam, Nadam, RMSprop\n",
    "import tensorflow as tf\n",
    "from hyperopt import STATUS_OK, STATUS_FAIL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import uuid\n",
    "import traceback\n",
    "import os\n",
    "\n",
    "\n",
    "TENSORBOARD_DIR = \"/home/cem/Desktop/TensorBoard\"\n",
    "WEIGHTS_DIR = \"/home/cem/Desktop/weights\"\n",
    "\n",
    "\n",
    "NB_CHANNELS = 1\n",
    "IMAGE_BORDER_LENGTH = 28\n",
    "NB_CLASSES = 47\n",
    "\n",
    "# (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "train = pd.read_csv('/home/cem/Desktop/emnist-balanced-train.csv', header=None)\n",
    "test = pd.read_csv('/home/cem/Desktop/emnist-balanced-test.csv', header=None)\n",
    "train_data = train.iloc[:, 1:]\n",
    "train_labels = train.iloc[:, 0]\n",
    "test_data = test.iloc[:, 1:]\n",
    "test_labels = test.iloc[:, 0]\n",
    "train_labels = keras.utils.to_categorical(train_labels)\n",
    "test_labels = keras.utils.to_categorical(test_labels)\n",
    "del train, test\n",
    "def rotate(image):\n",
    "    image = image.reshape([28, 28])\n",
    "    image = np.fliplr(image)\n",
    "    image = np.rot90(image)\n",
    "    return image.reshape([28 * 28])\n",
    "train_data = np.apply_along_axis(rotate, 1, train_data)\n",
    "test_data = np.apply_along_axis(rotate, 1, test_data)\n",
    "x_train=train_data\n",
    "y_train=train_labels\n",
    "x_test=test_data\n",
    "y_test=test_labels\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train/=255\n",
    "x_test/=255\n",
    "# You may want to reduce this considerably if you don't have a killer GPU:\n",
    "EPOCHS = 30\n",
    "STARTING_L2_REG = 0.0007\n",
    "\n",
    "OPTIMIZER_STR_TO_CLASS = {\n",
    "    'Adam': Adam,\n",
    "    'Nadam': Nadam,\n",
    "    'RMSprop': RMSprop\n",
    "}\n",
    "\n",
    "\n",
    "def build_and_train(hype_space, save_best_weights=False, log_for_tensorboard=False):\n",
    "    \"\"\"Build the deep CNN model and train it.\"\"\"\n",
    "    K.set_learning_phase(1)\n",
    "    K.set_image_data_format('channels_last')\n",
    "\n",
    "  \n",
    "    model = build_model(hype_space)\n",
    "\n",
    "    # K.set_learning_phase(1)\n",
    "\n",
    "    model_uuid = str(uuid.uuid4())[:5]\n",
    "\n",
    "    callbacks = []\n",
    "\n",
    "    # Weight saving callback:\n",
    "    if save_best_weights:\n",
    "        weights_save_path = os.path.join(\n",
    "            WEIGHTS_DIR, '{}.hdf5'.format(model_uuid))\n",
    "        print(\"Model's weights will be saved to: {}\".format(weights_save_path))\n",
    "        if not os.path.exists(WEIGHTS_DIR):\n",
    "            os.makedirs(WEIGHTS_DIR)\n",
    "\n",
    "        callbacks.append(keras.callbacks.ModelCheckpoint(\n",
    "            weights_save_path,\n",
    "            monitor='val_acc',\n",
    "            save_best_only=True, mode='max'))\n",
    "\n",
    "    # TensorBoard logging callback:\n",
    "    log_path = None\n",
    "    if log_for_tensorboard:\n",
    "        log_path = os.path.join(TENSORBOARD_DIR, model_uuid)\n",
    "        print(\"Tensorboard log files will be saved to: {}\".format(log_path))\n",
    "        if not os.path.exists(log_path):\n",
    "            os.makedirs(log_path)\n",
    "\n",
    "        # Right now Keras's TensorBoard callback and TensorBoard itself are not\n",
    "        # properly documented so we do not save embeddings (e.g.: for T-SNE).\n",
    "\n",
    "        # embeddings_metadata = {\n",
    "        #     # Dense layers only:\n",
    "        #     l.name: \"../10000_test_classes_labels_on_1_row_in_plain_text.tsv\"\n",
    "        #     for l in model.layers if 'dense' in l.name.lower()\n",
    "        # }\n",
    "\n",
    "        tb_callback = keras.callbacks.TensorBoard(\n",
    "            log_dir=log_path,\n",
    "            histogram_freq=2,\n",
    "            # write_images=True, # Enabling this line would require more than 5 GB at each `histogram_freq` epoch.\n",
    "            write_graph=True\n",
    "            # embeddings_freq=3,\n",
    "            # embeddings_layer_names=list(embeddings_metadata.keys()),\n",
    "            # embeddings_metadata=embeddings_metadata\n",
    "        )\n",
    "        tb_callback.set_model(model)\n",
    "        callbacks.append(tb_callback)\n",
    "\n",
    "    # Train net:\n",
    "    history = model.fit(\n",
    "        [x_train],\n",
    "        [y_train],\n",
    "        batch_size=int(hype_space['batch_size']),\n",
    "        epochs=EPOCHS,\n",
    "        shuffle=True,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks,\n",
    "        validation_data=([x_test], [y_test])\n",
    "    ).history\n",
    "\n",
    "    # Test net:\n",
    "    \n",
    "    K.set_learning_phase(0)\n",
    "    score = model.evaluate([x_test], [y_test], verbose=0)\n",
    "    max_acc = max(history['val_acc'])\n",
    " \n",
    "    model_name = \"model_{}_{}\".format(str(max_acc), str(uuid.uuid4())[:5])\n",
    "    print(\"Model name: {}\".format(model_name))\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "    # Note: to restore the model, you'll need to have a keras callback to\n",
    "    # save the best weights and not the final weights. Only the result is\n",
    "    # saved.\n",
    "    print(history.keys())\n",
    "    print(history)\n",
    "    print(\"score:\",score)\n",
    "    result = {\n",
    "        # We plug \"-val_fine_outputs_acc\" as a\n",
    "        # minimizing metric named 'loss' by Hyperopt.\n",
    "        'loss': -max_acc,\n",
    "        'real_loss': score[0],\n",
    "        # Fine stats:\n",
    "        'val_loss': min(history['val_loss']),\n",
    "        'val_acc': max(history['val_acc']),\n",
    "        'test_loss': score[0],\n",
    "        'test accuracy': score[1],\n",
    "       \n",
    "        # Misc:\n",
    "        'model_name': model_name,\n",
    "        'space': hype_space,\n",
    "        'history': history,\n",
    "        'status': STATUS_OK\n",
    "    }\n",
    "\n",
    "    print(\"RESULT:\")\n",
    "    print_json(result)\n",
    "\n",
    "    return model, model_name, result, log_path\n",
    "\n",
    "\n",
    "def build_model(hype_space):\n",
    "    \"\"\"Create model according to the hyperparameter space given.\"\"\"\n",
    "    print(\"Hyperspace:\")\n",
    "    print(hype_space)\n",
    "\n",
    "    input_layer = keras.layers.Input(\n",
    "        (IMAGE_BORDER_LENGTH, IMAGE_BORDER_LENGTH, NB_CHANNELS))\n",
    "\n",
    "    current_layer = random_image_mirror_left_right(input_layer)\n",
    "\n",
    "    if hype_space['first_conv'] is not None:\n",
    "        k = hype_space['first_conv']\n",
    "        current_layer = keras.layers.convolutional.Conv2D(\n",
    "            filters=16, kernel_size=(k, k), strides=(1, 1),\n",
    "            padding='same', activation=hype_space['activation'],\n",
    "            kernel_regularizer=keras.regularizers.l2(\n",
    "                STARTING_L2_REG * hype_space['l2_weight_reg_mult'])\n",
    "        )(current_layer)\n",
    "\n",
    "    # Core loop that stacks multiple conv+pool layers, with maybe some\n",
    "    # residual connections and other fluffs:\n",
    "    n_filters = int(40 * hype_space['conv_hiddn_units_mult'])\n",
    "    for i in range(hype_space['nb_conv_pool_layers']):\n",
    "        print(i)\n",
    "        print(n_filters)\n",
    "        print(current_layer._keras_shape)\n",
    "\n",
    "        current_layer = convolution(current_layer, n_filters, hype_space)\n",
    "        if hype_space['use_BN']:\n",
    "            current_layer = bn(current_layer)\n",
    "        print(current_layer._keras_shape)\n",
    "\n",
    "        deep_enough_for_res = hype_space['conv_pool_res_start_idx']\n",
    "        if i >= deep_enough_for_res and hype_space['residual'] is not None:\n",
    "            current_layer = residual(current_layer, n_filters, hype_space)\n",
    "            print(current_layer._keras_shape)\n",
    "\n",
    "        current_layer = auto_choose_pooling(\n",
    "            current_layer, n_filters, hype_space)\n",
    "        print(current_layer._keras_shape)\n",
    "\n",
    "        current_layer = dropout(current_layer, hype_space)\n",
    "\n",
    "        n_filters *= 2\n",
    "\n",
    "    # Fully Connected (FC) part:\n",
    "    current_layer = keras.layers.core.Flatten()(current_layer)\n",
    "    print(current_layer._keras_shape)\n",
    "\n",
    "    current_layer = keras.layers.core.Dense(\n",
    "        units=int(1000 * hype_space['fc_units_1_mult']),\n",
    "        activation=hype_space['activation'],\n",
    "        kernel_regularizer=keras.regularizers.l2(\n",
    "            STARTING_L2_REG * hype_space['l2_weight_reg_mult'])\n",
    "    )(current_layer)\n",
    "    print(current_layer._keras_shape)\n",
    "\n",
    "    current_layer = dropout(\n",
    "        current_layer, hype_space, for_convolution_else_fc=False)\n",
    "\n",
    "    if hype_space['one_more_fc'] is not None:\n",
    "        current_layer = keras.layers.core.Dense(\n",
    "            units=int(750 * hype_space['one_more_fc']),\n",
    "            activation=hype_space['activation'],\n",
    "            kernel_regularizer=keras.regularizers.l2(\n",
    "                STARTING_L2_REG * hype_space['l2_weight_reg_mult'])\n",
    "        )(current_layer)\n",
    "        print(current_layer._keras_shape)\n",
    "\n",
    "        current_layer = dropout(\n",
    "            current_layer, hype_space, for_convolution_else_fc=False)\n",
    "\n",
    "    # Two heads as outputs:\n",
    "    aoutputs = keras.layers.core.Dense(\n",
    "        units=NB_CLASSES,\n",
    "        activation=\"sigmoid\",\n",
    "        kernel_regularizer=keras.regularizers.l2(\n",
    "            STARTING_L2_REG * hype_space['l2_weight_reg_mult']),\n",
    "        name='aoutputs'\n",
    "    )(current_layer)\n",
    "\n",
    "    # Finalize model:\n",
    "    model = keras.models.Model(\n",
    "        inputs=[input_layer],\n",
    "        outputs=[aoutputs]\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer=OPTIMIZER_STR_TO_CLASS[hype_space['optimizer']](\n",
    "            lr=0.001 * hype_space['lr_rate_mult']\n",
    "        ),\n",
    "        loss='categorical_crossentropy',\n",
    "        loss_weights=[1.0],\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def random_image_mirror_left_right(input_layer):\n",
    "    \"\"\"\n",
    "    Flip each image left-right like in a mirror, randomly, even at test-time.\n",
    "\n",
    "    This acts as a data augmentation technique. See:\n",
    "    https://stackoverflow.com/questions/39574999/tensorflow-tf-image-functions-on-an-image-batch\n",
    "    \"\"\"\n",
    "    return keras.layers.core.Lambda(function=lambda batch_imgs: tf.map_fn(\n",
    "        lambda img: tf.image.random_flip_left_right(img), batch_imgs\n",
    "    )\n",
    "    )(input_layer)\n",
    "\n",
    "\n",
    "def bn(prev_layer):\n",
    "    \"\"\"Perform batch normalisation.\"\"\"\n",
    "    return keras.layers.normalization.BatchNormalization()(prev_layer)\n",
    "\n",
    "\n",
    "def dropout(prev_layer, hype_space, for_convolution_else_fc=True):\n",
    "    \"\"\"Add dropout after a layer.\"\"\"\n",
    "    if for_convolution_else_fc:\n",
    "        return keras.layers.core.Dropout(\n",
    "            rate=hype_space['conv_dropout_drop_proba']\n",
    "        )(prev_layer)\n",
    "    else:\n",
    "        return keras.layers.core.Dropout(\n",
    "            rate=hype_space['fc_dropout_drop_proba']\n",
    "        )(prev_layer)\n",
    "\n",
    "\n",
    "def convolution(prev_layer, n_filters, hype_space, force_ksize=None):\n",
    "    \"\"\"Basic convolution layer, parametrized by the hype_space.\"\"\"\n",
    "    if force_ksize is not None:\n",
    "        k = force_ksize\n",
    "    else:\n",
    "        k = int(round(hype_space['conv_kernel_size']))\n",
    "    return keras.layers.convolutional.Conv2D(\n",
    "        filters=n_filters, kernel_size=(k, k), strides=(1, 1),\n",
    "        padding='same', activation=hype_space['activation'],\n",
    "        kernel_regularizer=keras.regularizers.l2(\n",
    "            STARTING_L2_REG * hype_space['l2_weight_reg_mult'])\n",
    "    )(prev_layer)\n",
    "\n",
    "\n",
    "def residual(prev_layer, n_filters, hype_space):\n",
    "    \"\"\"Some sort of residual layer, parametrized by the hype_space.\"\"\"\n",
    "    current_layer = prev_layer\n",
    "    for i in range(int(round(hype_space['residual']))):\n",
    "        lin_current_layer = keras.layers.convolutional.Conv2D(\n",
    "            filters=n_filters, kernel_size=(1, 1), strides=(1, 1),\n",
    "            padding='same', activation='linear',\n",
    "            kernel_regularizer=keras.regularizers.l2(\n",
    "                STARTING_L2_REG * hype_space['l2_weight_reg_mult'])\n",
    "        )(current_layer)\n",
    "\n",
    "        layer_to_add = dropout(current_layer, hype_space)\n",
    "        layer_to_add = convolution(\n",
    "            layer_to_add, n_filters, hype_space,\n",
    "            force_ksize=int(round(hype_space['res_conv_kernel_size'])))\n",
    "\n",
    "        current_layer = keras.layers.add([\n",
    "            lin_current_layer,\n",
    "            layer_to_add\n",
    "        ])\n",
    "        if hype_space['use_BN']:\n",
    "            current_layer = bn(current_layer)\n",
    "    if not hype_space['use_BN']:\n",
    "        current_layer = bn(current_layer)\n",
    "\n",
    "    return bn(current_layer)\n",
    "\n",
    "\n",
    "def auto_choose_pooling(prev_layer, n_filters, hype_space):\n",
    "    \"\"\"Deal with pooling in convolution steps.\"\"\"\n",
    "    if hype_space['pooling_type'] == 'all_conv':\n",
    "        current_layer = convolution_pooling(\n",
    "            prev_layer, n_filters, hype_space)\n",
    "\n",
    "    elif hype_space['pooling_type'] == 'inception':\n",
    "        current_layer = inception_reduction(prev_layer, n_filters, hype_space)\n",
    "\n",
    "    elif hype_space['pooling_type'] == 'avg':\n",
    "        current_layer = keras.layers.pooling.AveragePooling2D(\n",
    "            pool_size=(2, 2)\n",
    "        )(prev_layer)\n",
    "\n",
    "    else:  # 'max'\n",
    "        current_layer = keras.layers.pooling.MaxPooling2D(\n",
    "            pool_size=(2, 2)\n",
    "        )(prev_layer)\n",
    "\n",
    "    return current_layer\n",
    "\n",
    "\n",
    "def convolution_pooling(prev_layer, n_filters, hype_space):\n",
    "    \"\"\"\n",
    "    Pooling with a convolution of stride 2.\n",
    "\n",
    "    See: https://arxiv.org/pdf/1412.6806.pdf\n",
    "    \"\"\"\n",
    "    current_layer = keras.layers.convolutional.Conv2D(\n",
    "        filters=n_filters, kernel_size=(3, 3), strides=(2, 2),\n",
    "        padding='same', activation='linear',\n",
    "        kernel_regularizer=keras.regularizers.l2(\n",
    "            STARTING_L2_REG * hype_space['l2_weight_reg_mult'])\n",
    "    )(prev_layer)\n",
    "\n",
    "    if hype_space['use_BN']:\n",
    "        current_layer = bn(current_layer)\n",
    "\n",
    "    return current_layer\n",
    "\n",
    "\n",
    "def inception_reduction(prev_layer, n_filters, hype_space):\n",
    "    \"\"\"\n",
    "    Reduction block, vaguely inspired from inception.\n",
    "\n",
    "    See: https://arxiv.org/pdf/1602.07261.pdf\n",
    "    \"\"\"\n",
    "    n_filters_a = int(n_filters * 0.33 + 1)\n",
    "    n_filters = int(n_filters * 0.4 + 1)\n",
    "\n",
    "    conv1 = convolution(prev_layer, n_filters_a, hype_space, force_ksize=3)\n",
    "    conv1 = convolution_pooling(prev_layer, n_filters, hype_space)\n",
    "\n",
    "    conv2 = convolution(prev_layer, n_filters_a, hype_space, 1)\n",
    "    conv2 = convolution(conv2, n_filters, hype_space, 3)\n",
    "    conv2 = convolution_pooling(conv2, n_filters, hype_space)\n",
    "\n",
    "    conv3 = convolution(prev_layer, n_filters, hype_space, force_ksize=1)\n",
    "    conv3 = keras.layers.pooling.MaxPooling2D(\n",
    "        pool_size=(3, 3), strides=(2, 2), padding='same'\n",
    "    )(conv3)\n",
    "\n",
    "    current_layer = keras.layers.concatenate([conv1, conv2, conv3], axis=-1)\n",
    "\n",
    "    return current_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
